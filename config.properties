# ===========================
# DEFAULT SETTINGS
# ===========================
[DEFAULT]=
# Limit training data fraction (0.0?1.0). Used only in dev mode.
development_mode=False
retrain_model=False
profiling_enabled=True
use_dataset_cache=False
# Subset sampling strategy (None, RollingSubsetSampler, CurriculumSampler)
subset_fraction=0.2
curriculum_phase_count=5
curriculum_unlock_every=1
sampler=None
# Maze solver used for baseline comparisons
solver=OptimizedBacktrackingMazeSolver
# solver = PledgeMazeSolver
# Model choice: GRU / LSTM / RNN
models=LSTM
use_attention=True
# Neural network input/output dimensions
input_size=7
output_size=3
# Training performance 5000000
training_samples=500
batch_size=32
max_num_workers=8
dataloader_workers=4
# Optimizer & scheduler
optimizer_type=Adam
scheduler_type=plateau
hidden_size=128
num_layers=2
num_epochs=40
patience=50
learning_rate=0.0001
weight_decay=0.001
lr_factor=0.5
improvement_threshold=0.005
# Solution depth limit
max_steps=100
[GRU]=
dummy_value=10
[LSTM]=
dummy_value=10
[RNN]=
dummy_value=10
# ===========================
# LLM SETTINGS
# ===========================
[LLM]=
# Ollama / ChatGPT / DeepSeek
provider=ChatGPT       
algorithm=Backtracking
model_name=gpt-5
temperature=0.5
max_tokens = 100
# ===========================
# MAZE GENERATION
# ===========================
[MAZE]=
min_size=5
max_size=18
loop_probability=0.02
num_mazes=500000
# ===========================
# GENETIC ALGORITHM
# ===========================
[GENETIC]=
# Population parameters
max_population_size=5000
crossover_rate=0.1
mutation_rate=1
generations=150
tournament_count=5
elitism_count=5
diversity_infusion=0.25
# ------------------------------------
# RAW FITNESS WEIGHTS (LEGACY SYSTEM)
# ------------------------------------
# These apply if you still use raw fitness scoring
path_diversity_bonus=5
diversity_penalty_weight=1
diversity_penalty_threshold=0.15
backtrack_penalty_weight=0.5
distance_penalty_weight=0.5
recover_bonus_weight=5
exploration_weight=2
invalid_move_penalty=2
loop_penalty_weight=5
bfs_distance_reward_weight=5
exit_weight=10
# ------------------------------------
# NORMALIZED FITNESS CONFIG (NEW SYSTEM)
# ------------------------------------
normalize_fitness=true
# Caps / bounds for normalization
invalid_penalty_cap=10
max_distance=150
diversity_penalty_cap=2.0
# Component weights for weighted-average normalized fitness
w_exit=50
w_exploration=1
w_bfs=10
w_recover=1
w_path_diversity=0.5
w_backtracks=0.1
w_loops=0.1
w_distance=2
w_invalid=0.1
w_diversity=2
# ------------------------------------
# OTHER GENETIC SETTINGS
# ------------------------------------
mutation_start_multiplier=0.5
mutation_stop_multiplier=1.5
mutation_rate_floor=0.01
mutation_rate_ceiling=0.35
species_distance_threshold=0.35
max_species=15
max_workers=0
random_seed=42
# Early stopping
patience=30
early_stopping_threshold=0.02
evolution_chromosomes=10
# ===========================
# FILE PATHS
# ===========================
[FILES]=
APP_PATH=.
OUTPUT=output/
INPUT=input/
GRU_MODEL=gru_model.pth
LSTM_MODEL=lstm_model.pth
RNN_MODEL=rnn_model.pth
TRAINING_MAZES=training_mazes.h5
VALIDATION_MAZES=validation_mazes.h5
MAZES=mazes.h5
LOSS_DATA=loss_data.csv
# ===========================
# MONITORING / OUTPUT
# ===========================
[MONITORING]=
visualization_mode=video
save_solution_movie=True
save_evolution_movie=False
wandb=False
dashboard=True
tensorboard=True
save_neural_network_diagram=True
save_last_loss_chart=True
generate_weights=True
save_mazes_as_pdf=True
generate_activations=False
print_mazes=True
sample_step=10
